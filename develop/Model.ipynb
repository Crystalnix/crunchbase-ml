{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the beginning we make required imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler, Imputer\n",
    "from sklearn_pandas import DataFrameMapper, CategoricalImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define pathes to our data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def path_to_data_file(path):\n",
    "    return os.path.normpath(os.path.join(os.path.abspath(os.path.curdir), path))\n",
    "\n",
    "train_file = \"../data/train_data.csv\"\n",
    "test_file = \"../data/test_data.csv\"\n",
    "data_file = \"../data/data.csv\"\n",
    "train_path = path_to_data_file(train_file)\n",
    "test_path = path_to_data_file(test_file)\n",
    "data_path = path_to_data_file(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class ValueImputer is used for imputing missed values with particular value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ValueImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, value, missing_values='NaN', copy=True):\n",
    "        self.value = value\n",
    "        self.missing_values = missing_values\n",
    "        self.copy = copy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        mask = self._get_mask(X, self.missing_values)\n",
    "        if self.copy:\n",
    "            X = X.copy()\n",
    "        X[mask] = self.value\n",
    "        return X\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_mask(X, value):\n",
    "        \"\"\"\n",
    "        Compute the boolean mask X == missing_values.\n",
    "        \"\"\"\n",
    "        if value == \"NaN\" or value is None or (isinstance(value, float) and np.isnan(value)):\n",
    "            return pd.isnull(X)\n",
    "        else:\n",
    "            return X == value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next class OnceFittedLabelBinarizer is modified usual LabelBinarizer. We make this modification because of behavior of DataFrameMapper used further. We need to train LabelBinarizer on full data to perform transformation for train set, but DataFrameMapper will fit binarizer on train data again, and some categories may be not learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnceFittedLabelBinarizer(LabelBinarizer):\n",
    "    def __init__(self, neg_label=0, pos_label=1, sparse_output=False):\n",
    "        super().__init__(neg_label, pos_label, sparse_output)\n",
    "        self.once_fitted = False\n",
    "\n",
    "    def fit(self, y):\n",
    "        if self.once_fitted:\n",
    "            return self\n",
    "        self.once_fitted = True\n",
    "        return super().fit(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class FundImputer is used for imputing missing values in column \"average_funded\". We supposed that average funding depends on number of funding rounds, so for imputing missing values for that feature RANSACRegressor was trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FundImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Impute average funds based on total rounds using RANSACRegressor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.clf = RANSACRegressor()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        frame = pd.DataFrame({'total_rounds': X[:, 0], 'average_funded': X[:, 1]})\n",
    "        grouped = frame.groupby('total_rounds').average_funded.mean()\n",
    "        rounds_funds = pd.DataFrame({'rounds': grouped.index, 'funded': grouped})\n",
    "        shape = (len(rounds_funds), 1)\n",
    "        self.clf.fit(rounds_funds.rounds.as_matrix().reshape(shape), rounds_funds.funded.as_matrix().reshape(shape))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        frame = pd.DataFrame({'total_rounds': X[:, 0], 'average_funded': X[:, 1]})\n",
    "        null_funded = frame.average_funded.isnull()\n",
    "        total_shape = (len(frame), 1)\n",
    "        null_funded_shape = (len(frame[null_funded]), 1)\n",
    "        prediction = self.clf.predict(frame[null_funded].total_rounds.as_matrix().reshape(null_funded_shape))\n",
    "        frame.loc[null_funded, 'average_funded'] = prediction.ravel()\n",
    "        transformed = frame.average_funded.as_matrix().reshape(total_shape)\n",
    "        return transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same technique was used for fixing average number of participants when company raised money, but had number of funding round participants equal to zero, with difference that number of participants was recovering by average funding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ParticipantsImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Impute participants number based on average funds using RANSACRegressor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.clf = RANSACRegressor()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        frame = pd.DataFrame({'average_funded': X[:, 0], 'average_participants': X[:, 1]})\n",
    "        funds_participants = frame[(frame.average_participants != 0.0) & frame.average_funded.notnull()]\n",
    "        shape = (len(funds_participants), 1)\n",
    "        features = funds_participants.average_funded.as_matrix().reshape(shape)\n",
    "        ground_truth = funds_participants.average_participants.as_matrix().reshape(shape)\n",
    "        self.clf.fit(features, ground_truth)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        frame = pd.DataFrame({'average_funded': X[:, 0], 'average_participants': X[:, 1]})\n",
    "        null_participants = (frame.average_participants == 0.0) & frame.average_funded.notnull()\n",
    "        total_shape = (len(frame), 1)\n",
    "        null_funded_shape = (len(frame[null_participants]), 1)\n",
    "        prediction = self.clf.predict(frame[null_participants].average_funded.as_matrix().reshape(null_funded_shape))\n",
    "        frame.loc[null_participants, 'average_participants'] = prediction.ravel()\n",
    "        transformed = frame.average_participants.as_matrix().reshape(total_shape)\n",
    "        return transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start learning. First, we train ours label binarizers on whole data to not miss any categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "category_binarizer = OnceFittedLabelBinarizer()\n",
    "country_binarizer = OnceFittedLabelBinarizer()\n",
    "state_binarizer = OnceFittedLabelBinarizer()\n",
    "category_mapper = DataFrameMapper([\n",
    "    (['category_code'], [CategoricalImputer(), category_binarizer]),\n",
    "    (['country_code'], [CategoricalImputer(), country_binarizer]),\n",
    "    (['state_code'], [CategoricalImputer(), state_binarizer]),\n",
    "])\n",
    "category_mapper.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we map ours columns to corresponding transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapper = DataFrameMapper([\n",
    "    (['category_code'], [CategoricalImputer(), category_binarizer], {'alias': 'category'}),\n",
    "    (['country_code'], [CategoricalImputer(), country_binarizer], {'alias': 'country'}),\n",
    "    (['state_code'], [CategoricalImputer(), state_binarizer], {'alias': 'state'}),\n",
    "    (['mba_degree'], [ValueImputer(0), StandardScaler()]),\n",
    "    (['phd_degree'], [ValueImputer(0), StandardScaler()]),\n",
    "    (['ms_degree'], [ValueImputer(0), StandardScaler()]),\n",
    "    (['other_degree'], [ValueImputer(0)]),\n",
    "    (['age'], [Imputer(), StandardScaler()]),\n",
    "    (['offices'], [ValueImputer(1.0), StandardScaler()]),\n",
    "    (['products_number'], [ValueImputer(1.0), StandardScaler()]),\n",
    "    (['average_funded', 'average_participants'], [ParticipantsImputer(), StandardScaler()],\n",
    "     {'alias': 'average_participants'}),\n",
    "    (['total_rounds'], None),\n",
    "    (['ipo'], None),\n",
    "    (['is_closed'], None),\n",
    "    (['total_rounds', 'average_funded'], [FundImputer(), StandardScaler()], {'alias': 'average_funded'}),\n",
    "    (['acquired_companies'], [ValueImputer(0)]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the next step we determine params grid that will be used later in a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVC_C_grid = [10 ** i for i in range(-3, 4)]\n",
    "SVC_gamma_grid = [10 ** i for i in range(-3, 1)] + ['auto']\n",
    "MLP_hidden_layer_sizes = [[25], [50], [75], [100], [50, 25], [75, 50], [100, 75], [75, 50, 25], [100, 75, 50]]\n",
    "MLP_activation = ['logistic', 'tanh', 'relu']\n",
    "grid = [{'clf': [GradientBoostingClassifier()], 'clf__n_estimators': [20 * i for i in range(5, 8)],\n",
    "         'clf__max_depth': [i + 3 for i in range(2, 6)]},\n",
    "        {'clf': [SVC(kernel='rbf', class_weight='balanced')], 'clf__C': SVC_C_grid, 'clf__gamma':SVC_gamma_grid},\n",
    "        {'clf': [SVC(kernel='poly', class_weight='balanced')], 'clf__C': SVC_C_grid, 'clf__gamma':SVC_gamma_grid,\n",
    "         'clf__degree': list(range(3, 6))},\n",
    "        {'clf': [MLPClassifier()], 'clf__hidden_layer_sizes': MLP_hidden_layer_sizes, 'clf__activation': MLP_activation,\n",
    "         'clf__alpha': [10 ** i for i in range(-1, 3)]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n",
    "X_train = train_data.drop(['company_id', 'is_acquired'], axis=1)\n",
    "Y_train = train_data.is_acquired.as_matrix()\n",
    "X_test = test_data.drop(['company_id', 'is_acquired'], axis=1)\n",
    "Y_test = test_data.is_acquired.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All preparations are completed, and we are ready to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = [('fill_nan', mapper), ('clf', GradientBoostingClassifier())]\n",
    "pipe = Pipeline(estimators)\n",
    "clf = GridSearchCV(pipe, grid, scoring='f1', cv=StratifiedKFold(n_splits=3, shuffle=True))\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Best score: \", clf.best_score_)\n",
    "print(\"Best params: \", clf.best_params_)\n",
    "\n",
    "prediction = clf.predict(X_test)\n",
    "print(f1_score(Y_test, prediction))\n",
    "\n",
    "recall = (Y_test & prediction).sum() / Y_test.sum()\n",
    "precision = (Y_test & prediction).sum() / prediction.sum()\n",
    "print(\"recall: \", recall)\n",
    "print(\"precision: \", precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
